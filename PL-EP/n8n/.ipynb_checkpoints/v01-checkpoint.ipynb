{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n8n Templates CSV Analysis\n",
    "\n",
    "This notebook reads and analyzes the n8n_Templates.csv file to explore the available workflow templates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "try:\n",
    "    df = pd.read_csv('n8n_Templates.csv')\n",
    "    print(\"‚úÖ File loaded successfully!\")\n",
    "    print(f\"üìä Dataset shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå File 'n8n_Templates.csv' not found. Please ensure it's in the same directory as this notebook.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"\\nüìã First 5 rows of the dataset:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset information\n",
    "print(\"\\nüìà Dataset Info:\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(\"\\nüìù Column names:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and missing values\n",
    "print(\"\\nüîç Data Types and Missing Values:\")\n",
    "df_info = pd.DataFrame({\n",
    "    'Data Type': df.dtypes,\n",
    "    'Non-Null Count': df.count(),\n",
    "    'Null Count': df.isnull().sum(),\n",
    "    'Null Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "})\n",
    "display(df_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary for numerical columns\n",
    "print(\"\\nüìä Statistical Summary (Numerical Columns):\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary for categorical columns\n",
    "print(\"\\nüìä Summary for Categorical Columns:\")\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\nüìå {col}:\")\n",
    "    print(f\"   Unique values: {df[col].nunique()}\")\n",
    "    if df[col].nunique() <= 10:  # Only show value counts if not too many unique values\n",
    "        print(f\"   Value counts:\")\n",
    "        print(df[col].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of numerical columns\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "if len(numerical_cols) > 0:\n",
    "    print(\"\\nüìà Distribution of Numerical Columns:\")\n",
    "    \n",
    "    # Calculate number of subplots needed\n",
    "    n_cols = min(3, len(numerical_cols))\n",
    "    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "    if n_rows == 1:\n",
    "        axes = [axes] if n_cols == 1 else axes\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(numerical_cols):\n",
    "        if i < len(axes):\n",
    "            df[col].hist(bins=30, ax=axes[i], alpha=0.7)\n",
    "            axes[i].set_title(f'Distribution of {col}')\n",
    "            axes[i].set_xlabel(col)\n",
    "            axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(len(numerical_cols), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No numerical columns found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top categories for categorical columns (for columns with reasonable number of unique values)\n",
    "print(\"\\nüìä Top Categories in Categorical Columns:\")\n",
    "\n",
    "for col in categorical_cols:\n",
    "    unique_count = df[col].nunique()\n",
    "    if 1 < unique_count <= 20:  # Only plot if reasonable number of categories\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Get value counts and plot\n",
    "        value_counts = df[col].value_counts().head(10)\n",
    "        \n",
    "        if len(value_counts) > 0:\n",
    "            bars = plt.bar(range(len(value_counts)), value_counts.values, alpha=0.7)\n",
    "            plt.title(f'Top {len(value_counts)} Categories in {col}')\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel('Count')\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar, count in zip(bars, value_counts.values):\n",
    "                plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n",
    "                        str(count), ha='center', va='bottom')\n",
    "            \n",
    "            plt.xticks(range(len(value_counts)), value_counts.index, rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(\"\\nüîç Data Quality Check:\")\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "# Check for empty strings\n",
    "empty_strings = (df.applymap(lambda x: x == '')).sum().sum()\n",
    "print(f\"Number of empty strings: {empty_strings}\")\n",
    "\n",
    "# Check for whitespace-only strings\n",
    "whitespace_only = (df.applymap(lambda x: isinstance(x, str) and x.strip() == '')).sum().sum()\n",
    "print(f\"Number of whitespace-only strings: {whitespace_only}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sample Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display random sample of the data\n",
    "print(\"\\nüé≤ Random Sample of 5 Rows:\")\n",
    "display(df.sample(5, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last few rows\n",
    "print(\"\\nüìã Last 5 rows of the dataset:\")\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Cleaned Data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option to save cleaned data\n",
    "save_cleaned = input(\"\\nüíæ Do you want to save a cleaned version of the data? (y/n): \")\n",
    "\n",
    "if save_cleaned.lower() == 'y':\n",
    "    # Remove completely empty columns\n",
    "    cleaned_df = df.dropna(axis=1, how='all')\n",
    "    \n",
    "    # Fill or drop other missing values based on your needs\n",
    "    # For example: cleaned_df = cleaned_df.fillna('Unknown')\n",
    "    \n",
    "    # Save to new CSV\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f'n8n_Templates_cleaned_{timestamp}.csv'\n",
    "    cleaned_df.to_csv(filename, index=False)\n",
    "    print(f\"‚úÖ Cleaned data saved as: {filename}\")\n",
    "else:\n",
    "    print(\"‚ùå Data export cancelled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìã ANALYSIS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"üìä Total Records: {df.shape[0]:,}\")\n",
    "print(f\"üìù Total Columns: {df.shape[1]}\")\n",
    "print(f\"üî¢ Numerical Columns: {len(numerical_cols)}\")\n",
    "print(f\"üìù Categorical Columns: {len(categorical_cols)}\")\n",
    "print(f\"‚ö†Ô∏è  Missing Values: {df.isnull().sum().sum()}\")\n",
    "print(f\"üîç Duplicate Rows: {df.duplicated().sum()}\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}