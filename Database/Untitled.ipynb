{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "455482bf-f16e-4867-bc31-d27bc1557507",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'songId' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_audio_synced_video\u001b[39m(song_id\u001b[38;5;241m=\u001b[39msongId, plot_analysis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create video with audio-analysis-based lyrics synchronization - WITH DURATION LIMIT\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Get song data\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'songId' is not defined"
     ]
    }
   ],
   "source": [
    "def create_audio_synced_video(song_id=songId, plot_analysis=True, max_duration=None):\n",
    "    \"\"\"Create video with audio-analysis-based lyrics synchronization - WITH DURATION LIMIT\"\"\"\n",
    "    # Get song data\n",
    "    sql = '''\n",
    "    SELECT * FROM songs\n",
    "    WHERE name LIKE \"imagine\"\n",
    "    '''\n",
    "    songs = pd.read_sql(sql, engine)\n",
    "    songId = songs['id'].iloc[0]\n",
    "    try:\n",
    "        # Get song data\n",
    "        query = f\"\"\"\n",
    "        SELECT s.name as song_name, s.location as audio_file,\n",
    "               l.content as lyrics, a.first_name, a.last_name\n",
    "        FROM songs s \n",
    "        JOIN lyrics l ON s.id = l.song_id \n",
    "        JOIN artists a ON s.artist_id = a.id \n",
    "        WHERE s.id = {song_id}\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.read_sql(query, engine)\n",
    "        song_data = df.iloc[0]\n",
    "        \n",
    "        print(f\"üéµ Creating AUDIO-SYNCED video for: {song_data['song_name']}\")\n",
    "        \n",
    "        # Construct file paths\n",
    "        audio_dir = os.path.join(r\"C:\\ruby\\music\\public\\uploads\\song\\location\", str(song_id))\n",
    "        audio_path = os.path.join(audio_dir, song_data['audio_file'])\n",
    "        background_image_path = os.path.join(audio_dir, \"Folder.jpg\")\n",
    "        \n",
    "        print(f\"üîä Audio: {os.path.basename(audio_path)}\")\n",
    "        print(f\"üñºÔ∏è Background: {os.path.basename(background_image_path)}\")\n",
    "        \n",
    "        if not os.path.exists(audio_path):\n",
    "            print(\"‚ùå Audio file not found\")\n",
    "            return None\n",
    "        \n",
    "        # Perform audio analysis\n",
    "        audio_analysis = detect_vocal_segments(audio_path, plot_analysis=plot_analysis)\n",
    "        \n",
    "        # Load audio clip\n",
    "        audio_clip = AudioFileClip(audio_path)\n",
    "        full_duration = audio_analysis.get('duration', audio_clip.duration)\n",
    "        \n",
    "        # APPLY DURATION LIMIT\n",
    "        if max_duration:\n",
    "            duration = min(max_duration, full_duration)\n",
    "            print(f\"‚è±Ô∏è Using LIMITED duration: {duration:.1f}s (max_duration={max_duration}s)\")\n",
    "        else:\n",
    "            duration = full_duration\n",
    "            print(f\"‚è±Ô∏è Using FULL duration: {duration:.1f}s\")\n",
    "        \n",
    "        # Trim audio if needed\n",
    "        if max_duration and full_duration > max_duration:\n",
    "            audio_clip = audio_clip.subclip(0, duration)\n",
    "        \n",
    "        # Assign lyrics to timing segments (within the limited duration)\n",
    "        lyrics_with_timing = assign_lyrics_to_segments(song_data['lyrics'], audio_analysis)\n",
    "        \n",
    "        if not lyrics_with_timing:\n",
    "            print(\"‚ùå Could not assign lyrics timing\")\n",
    "            return None\n",
    "        \n",
    "        # Filter lyrics to only include those within the limited duration\n",
    "        if max_duration:\n",
    "            lyrics_with_timing = [lyric for lyric in lyrics_with_timing if lyric['start_time'] < duration]\n",
    "            # Adjust the end time of the last lyric to match the limited duration\n",
    "            if lyrics_with_timing and lyrics_with_timing[-1]['end_time'] > duration:\n",
    "                lyrics_with_timing[-1]['end_time'] = duration\n",
    "        \n",
    "        print(f\"üìù Successfully assigned {len(lyrics_with_timing)} lyrics lines\")\n",
    "        print(f\"‚è±Ô∏è Video duration: {duration:.1f}s ({duration/60:.1f} minutes)\")\n",
    "        \n",
    "        # Video settings\n",
    "        fps = 24\n",
    "        width, height = 640, 480\n",
    "        \n",
    "        def make_synced_frame(t):\n",
    "            try:\n",
    "                # Load background\n",
    "                if os.path.exists(background_image_path):\n",
    "                    bg_image = Image.open(background_image_path)\n",
    "                    bg_image = bg_image.resize((width, height), Image.Resampling.LANCZOS)\n",
    "                    frame = np.array(bg_image)\n",
    "                else:\n",
    "                    frame = np.full((height, width, 3), [40, 40, 80], dtype=np.uint8)\n",
    "                \n",
    "                # Convert to PIL for text drawing\n",
    "                pil_img = Image.fromarray(frame)\n",
    "                draw = ImageDraw.Draw(pil_img)\n",
    "                \n",
    "                # Load font\n",
    "                try:\n",
    "                    font = ImageFont.truetype(\"arial.ttf\", 32)\n",
    "                except:\n",
    "                    try:\n",
    "                        font = ImageFont.truetype(\"C:/Windows/Fonts/arial.ttf\", 32)\n",
    "                    except:\n",
    "                        font = ImageFont.load_default()\n",
    "                \n",
    "                # Get current lyric based on audio analysis\n",
    "                current_line = get_current_lyric(t, lyrics_with_timing)\n",
    "                \n",
    "                if current_line:\n",
    "                    # Calculate text position\n",
    "                    try:\n",
    "                        bbox = draw.textbbox((0, 0), current_line, font=font)\n",
    "                    except AttributeError:\n",
    "                        bbox = draw.textsize(current_line, font=font)\n",
    "                        bbox = (0, 0, bbox[0], bbox[1])\n",
    "                    \n",
    "                    text_width = bbox[2] - bbox[0]\n",
    "                    text_height = bbox[3] - bbox[1]\n",
    "                    x = (width - text_width) // 2\n",
    "                    y = (height - text_height) // 2\n",
    "                    \n",
    "                    # Semi-transparent background for text\n",
    "                    padding = 10\n",
    "                    draw.rectangle([\n",
    "                        x - padding, y - padding,\n",
    "                        x + text_width + padding, y + text_height + padding\n",
    "                    ], fill=(0, 0, 0, 180))\n",
    "                    \n",
    "                    # Text with shadow for readability\n",
    "                    shadow_color = (0, 0, 0)\n",
    "                    text_color = (255, 255, 255)\n",
    "                    \n",
    "                    # Shadow\n",
    "                    draw.text((x+2, y+2), current_line, font=font, fill=shadow_color)\n",
    "                    # Main text\n",
    "                    draw.text((x, y), current_line, font=font, fill=text_color)\n",
    "                \n",
    "                return np.array(pil_img)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Frame error at {t:.1f}s: {e}\")\n",
    "                return np.zeros((height, width, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Create video\n",
    "        print(\"üé¨ Creating audio-synced video frames...\")\n",
    "        video = VideoClip(make_synced_frame, duration=duration)\n",
    "        video = video.set_audio(audio_clip)\n",
    "        \n",
    "        # Export\n",
    "        output_dir = '../data/videos'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Include duration in filename if limited\n",
    "        if max_duration:\n",
    "            output_file = os.path.join(output_dir, f\"{song_data['song_name']}_audio_synced_{max_duration}s.mp4\")\n",
    "        else:\n",
    "            output_file = os.path.join(output_dir, f\"{song_data['song_name']}_audio_synced_full.mp4\")\n",
    "        \n",
    "        print(\"üìπ Exporting audio-synced video...\")\n",
    "        video.write_videofile(\n",
    "            output_file, \n",
    "            fps=fps, \n",
    "            codec='libx264',\n",
    "            audio_codec='aac',\n",
    "            verbose=False,\n",
    "            logger=None\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ AUDIO-SYNCED video created: {output_file}\")\n",
    "        print(f\"üìä File size: {os.path.getsize(output_file) / (1024*1024):.1f} MB\")\n",
    "        \n",
    "        # Display timing information\n",
    "        print(\"\\nüìã Lyrics Timing Summary:\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, lyric in enumerate(lyrics_with_timing):\n",
    "            print(f\"{i+1:2d}. {lyric['start_time']:5.1f}s - {lyric['end_time']:5.1f}s: {lyric['text'][:40]}{'...' if len(lyric['text']) > 40 else ''}\")\n",
    "        \n",
    "        # Clean up\n",
    "        video.close()\n",
    "        audio_clip.close()\n",
    "        \n",
    "        return output_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Audio-synced video error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Also fix the tempo formatting error in detect_vocal_segments function:\n",
    "def detect_vocal_segments(audio_path, plot_analysis=False):\n",
    "    \"\"\"Use librosa to detect vocal segments and onsets - FIXED TEMPO FORMATTING\"\"\"\n",
    "    try:\n",
    "        print(\"üé§ Analyzing audio for vocal segments...\")\n",
    "        \n",
    "        # Load audio file\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "        duration = librosa.get_duration(y=y, sr=sr)\n",
    "        \n",
    "        print(f\"üìä Audio loaded: {duration:.2f}s, SR: {sr}Hz\")\n",
    "        \n",
    "        # Extract features for vocal detection\n",
    "        print(\"üìä Extracting audio features...\")\n",
    "        \n",
    "        # Harmonic-percussive source separation\n",
    "        y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "        \n",
    "        # Detect onsets (places where vocals/instruments start)\n",
    "        onset_frames = librosa.onset.onset_detect(\n",
    "            y=y, \n",
    "            sr=sr, \n",
    "            hop_length=512, \n",
    "            backtrack=True,\n",
    "            delta=0.1\n",
    "        )\n",
    "        onset_times = librosa.frames_to_time(onset_frames, sr=sr, hop_length=512)\n",
    "        \n",
    "        # Detect beats for rhythm analysis - FIX TEMPO FORMATTING\n",
    "        tempo_beat = librosa.beat.beat_track(y=y, sr=sr, hop_length=512)\n",
    "        tempo = tempo_beat[0]  # Extract tempo value\n",
    "        beat_frames = tempo_beat[1]  # Extract beat frames\n",
    "        beat_times = librosa.frames_to_time(beat_frames, sr=sr, hop_length=512)\n",
    "        \n",
    "        # Vocal activity detection using spectral features\n",
    "        stft = librosa.stft(y_harmonic)\n",
    "        spectral_centroids = librosa.feature.spectral_centroid(y=y_harmonic, sr=sr)\n",
    "        \n",
    "        # FIX: Handle the shape of spectral_centroids properly\n",
    "        print(f\"üìê Spectral centroids shape: {spectral_centroids.shape}\")\n",
    "        \n",
    "        # Flatten and normalize features\n",
    "        spectral_flat = spectral_centroids.flatten()\n",
    "        spectral_centroids_normalized = (spectral_flat - np.min(spectral_flat)) / (np.max(spectral_flat) - np.min(spectral_flat))\n",
    "        \n",
    "        # Create time array for features - FIXED\n",
    "        times = librosa.times_like(spectral_centroids, sr=sr, hop_length=512)\n",
    "        times_flat = times.flatten()\n",
    "        \n",
    "        print(f\"üìê Times shape: {times.shape}, Normalized centroids shape: {spectral_centroids_normalized.shape}\")\n",
    "        \n",
    "        # Detect vocal segments based on spectral features - FIXED\n",
    "        vocal_segments = []\n",
    "        current_segment = None\n",
    "        vocal_threshold = 0.4  # Adjusted threshold\n",
    "        \n",
    "        # Ensure arrays are the same length\n",
    "        min_length = min(len(times_flat), len(spectral_centroids_normalized))\n",
    "        \n",
    "        for i in range(min_length):\n",
    "            time = times_flat[i]\n",
    "            centroid = spectral_centroids_normalized[i]\n",
    "            \n",
    "            if centroid > vocal_threshold:\n",
    "                if current_segment is None:\n",
    "                    current_segment = {'start': time, 'end': time}\n",
    "                else:\n",
    "                    current_segment['end'] = time\n",
    "            else:\n",
    "                if current_segment is not None:\n",
    "                    # Only keep segments longer than 0.5 seconds\n",
    "                    if current_segment['end'] - current_segment['start'] > 0.5:\n",
    "                        vocal_segments.append(current_segment)\n",
    "                    current_segment = None\n",
    "        \n",
    "        # Add the last segment if exists\n",
    "        if current_segment is not None and current_segment['end'] - current_segment['start'] > 0.5:\n",
    "            vocal_segments.append(current_segment)\n",
    "        \n",
    "        # If no vocal segments detected, use a fallback approach\n",
    "        if not vocal_segments:\n",
    "            print(\"‚ö†Ô∏è No vocal segments detected, using onset-based segmentation\")\n",
    "            # Use onsets to create segments\n",
    "            for i in range(len(onset_times) - 1):\n",
    "                vocal_segments.append({\n",
    "                    'start': onset_times[i],\n",
    "                    'end': onset_times[i + 1]\n",
    "                })\n",
    "        \n",
    "        # Plot analysis if requested\n",
    "        if plot_analysis:\n",
    "            plot_audio_analysis(y, sr, times_flat[:min_length], spectral_centroids_normalized[:min_length], onset_times, vocal_segments)\n",
    "        \n",
    "        print(f\"‚úÖ Detected {len(vocal_segments)} vocal segments\")\n",
    "        print(f\"‚úÖ Detected {len(onset_times)} musical onsets\")\n",
    "        print(f\"üéµ Estimated tempo: {tempo:.1f} BPM\")  # FIXED: Now tempo is a float\n",
    "        \n",
    "        return {\n",
    "            'duration': duration,\n",
    "            'onset_times': onset_times,\n",
    "            'beat_times': beat_times,\n",
    "            'vocal_segments': vocal_segments,\n",
    "            'tempo': tempo\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Audio analysis error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Return basic analysis with duration only\n",
    "        return {\n",
    "            'duration': 185,  # Fallback duration for Imagine\n",
    "            'onset_times': [],\n",
    "            'beat_times': [],\n",
    "            'vocal_segments': [{'start': 5, 'end': 180}],  # Assume most of song has vocals\n",
    "            'tempo': 120\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806143cf-1912-49ef-9385-e341ac2b311c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
