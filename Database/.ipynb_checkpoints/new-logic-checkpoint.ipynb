{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20dd408c-1217-4646-aaab-8a47ebf98120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your database connection\n",
    "engine = create_engine('mysql+pymysql://root@localhost:3306/music_development')\n",
    "data_path = '../data/'\n",
    "\n",
    "# Get song data\n",
    "sql = '''\n",
    "SELECT * FROM songs\n",
    "WHERE name LIKE \"The Older I Get\"\n",
    "'''\n",
    "songs = pd.read_sql(sql, engine)\n",
    "songId = songs['id'].iloc[0]\n",
    "\n",
    "# Get lyrics\n",
    "sql = f'SELECT * FROM lyrics WHERE song_id = {songId}'\n",
    "lyrics = pd.read_sql(sql, engine)\n",
    "lyrics_content = lyrics.content.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a1163c-b18e-4140-a7bf-4e899e8ce2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full lyrics content:\n",
      "==================================================\n",
      "18,the older i get \n",
      "22,the more i think \n",
      "26,you only get a minute \n",
      "29,better live while you're in it \n",
      "30,cause it's gone in a blink \n",
      "34,and the older i get\n",
      "38,the truer it is \n",
      "42,it's the people you love  \n",
      "46,not the money and stuff\n",
      "47,that makes you rich \n",
      "51,and if they found a fountain of youth \n",
      "54,i wouldn't drink a drop  \n",
      "58,and that's the truth \n",
      "60,funny how it feels i'm just getting to  \n",
      "63,my best years yet\n",
      "68,the older i get \n",
      "72,fewer friends i have\n",
      "76,but you don't need a lot and the ones \n",
      "79,that you've got\n",
      "80,have always got your back\n",
      "84,and the older i get \n",
      "89,the better i am \n",
      "93,and knowing when to give  \n",
      "96,and when to just not give a damn \n",
      "101,and if they found a fountain of youth \n",
      "105,i wouldn't drink a drop \n",
      "109,and that's the truth \n",
      "110,funny how it feels i'm just getting to  \n",
      "114,my best years yet\n",
      "118,the older i get \n",
      "136,[Music}\n",
      "152,and i don't mind all the lies \n",
      "156,from all the times i've \n",
      "158,laughed and cried\n",
      "162,souvenirs and little signs \n",
      "165,of the life i've lived \n",
      "170,the older i get\n",
      "173,the longer i pray \n",
      "178,i don't know why \n",
      "180,i guess that i've \n",
      "182,got more to say \n",
      "186,and the older i get \n",
      "190,the more thankful i feel\n",
      "194,for the life i've had and all \n",
      "198,the life i'm living still \n"
     ]
    }
   ],
   "source": [
    "# Method 2: Direct string printing with proper formatting\n",
    "sql = f\"\"\"\n",
    "SELECT id, song_id, content \n",
    "FROM lyrics \n",
    "WHERE song_id = {songId}\n",
    "\"\"\"\n",
    "lyrics = pd.read_sql(sql, engine)\n",
    "# Get the lyrics content\n",
    "lyrics_content = lyrics.content.iloc[0]\n",
    "\n",
    "# Print with proper line breaks (replace \\r\\n with actual newlines)\n",
    "print(\"Full lyrics content:\")\n",
    "print(\"=\" * 50)\n",
    "print(lyrics_content.replace('\\r\\n', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a961c11f-95af-4097-ac78-28892d8c0755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also fix the tempo formatting error in detect_vocal_segments function:\n",
    "def detect_vocal_segments(audio_path, plot_analysis=False):\n",
    "    \"\"\"Use librosa to detect vocal segments and onsets - FIXED TEMPO FORMATTING\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸ¤ Analyzing audio for vocal segments...\")\n",
    "        \n",
    "        # Load audio file\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "        duration = librosa.get_duration(y=y, sr=sr)\n",
    "        \n",
    "        print(f\"ğŸ“Š Audio loaded: {duration:.2f}s, SR: {sr}Hz\")\n",
    "        \n",
    "        # Extract features for vocal detection\n",
    "        print(\"ğŸ“Š Extracting audio features...\")\n",
    "        \n",
    "        # Harmonic-percussive source separation\n",
    "        y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "        \n",
    "        # Detect onsets (places where vocals/instruments start)\n",
    "        onset_frames = librosa.onset.onset_detect(\n",
    "            y=y, \n",
    "            sr=sr, \n",
    "            hop_length=512, \n",
    "            backtrack=True,\n",
    "            delta=0.1\n",
    "        )\n",
    "        onset_times = librosa.frames_to_time(onset_frames, sr=sr, hop_length=512)\n",
    "\n",
    "        # Detect beats for rhythm analysis - FIX TEMPO FORMATTING\n",
    "        tempo_beat = librosa.beat.beat_track(y=y, sr=sr, hop_length=512)\n",
    "        tempo = tempo_beat[0]  # Extract tempo value\n",
    "        beat_frames = tempo_beat[1]  # Extract beat frames\n",
    "        beat_times = librosa.frames_to_time(beat_frames, sr=sr, hop_length=512)\n",
    "        \n",
    "        # Vocal activity detection using spectral features\n",
    "        stft = librosa.stft(y_harmonic)\n",
    "        spectral_centroids = librosa.feature.spectral_centroid(y=y_harmonic, sr=sr)\n",
    "        \n",
    "        # FIX: Handle the shape of spectral_centroids properly\n",
    "        print(f\"ğŸ“ Spectral centroids shape: {spectral_centroids.shape}\")\n",
    "        \n",
    "        # Flatten and normalize features\n",
    "        spectral_flat = spectral_centroids.flatten()\n",
    "        spectral_centroids_normalized = (spectral_flat - np.min(spectral_flat)) / (np.max(spectral_flat) - np.min(spectral_flat))\n",
    "        \n",
    "        # Create time array for features - FIXED\n",
    "        times = librosa.times_like(spectral_centroids, sr=sr, hop_length=512)\n",
    "        times_flat = times.flatten()\n",
    "\n",
    "        print(f\"ğŸ“ Times shape: {times.shape}, Normalized centroids shape: {spectral_centroids_normalized.shape}\")\n",
    "        \n",
    "        # Detect vocal segments based on spectral features - FIXED\n",
    "        vocal_segments = []\n",
    "        current_segment = None\n",
    "        vocal_threshold = 0.4  # Adjusted threshold\n",
    "        \n",
    "        # Ensure arrays are the same length\n",
    "        min_length = min(len(times_flat), len(spectral_centroids_normalized))\n",
    "        \n",
    "        for i in range(min_length):\n",
    "            time = times_flat[i]\n",
    "            centroid = spectral_centroids_normalized[i]\n",
    "            \n",
    "            if centroid > vocal_threshold:\n",
    "                if current_segment is None:\n",
    "                    current_segment = {'start': time, 'end': time}\n",
    "                else:\n",
    "                    current_segment['end'] = time\n",
    "            else:\n",
    "                if current_segment is not None:\n",
    "                    # Only keep segments longer than 0.5 seconds\n",
    "                    if current_segment['end'] - current_segment['start'] > 0.5:\n",
    "                        vocal_segments.append(current_segment)\n",
    "                    current_segment = None\n",
    "\n",
    "        # Add the last segment if exists\n",
    "        if current_segment is not None and current_segment['end'] - current_segment['start'] > 0.5:\n",
    "            vocal_segments.append(current_segment)\n",
    "        \n",
    "        # If no vocal segments detected, use a fallback approach\n",
    "        if not vocal_segments:\n",
    "            print(\"âš ï¸ No vocal segments detected, using onset-based segmentation\")\n",
    "            # Use onsets to create segments\n",
    "            for i in range(len(onset_times) - 1):\n",
    "                vocal_segments.append({\n",
    "                    'start': onset_times[i],\n",
    "                    'end': onset_times[i + 1]\n",
    "                })\n",
    "        \n",
    "        # Plot analysis if requested\n",
    "        if plot_analysis:\n",
    "            plot_audio_analysis(y, sr, times_flat[:min_length], spectral_centroids_normalized[:min_length], onset_times, vocal_segments)\n",
    "        \n",
    "        print(f\"âœ… Detected {len(vocal_segments)} vocal segments\")\n",
    "        print(f\"âœ… Detected {len(onset_times)} musical onsets\")\n",
    "        print(f\"ğŸµ Estimated tempo: {tempo:.1f} BPM\")  # FIXED: Now tempo is a float\n",
    "\n",
    "        return {\n",
    "            'duration': duration,\n",
    "            'onset_times': onset_times,\n",
    "            'beat_times': beat_times,\n",
    "            'vocal_segments': vocal_segments,\n",
    "            'tempo': tempo\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Audio analysis error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Return basic analysis with duration only\n",
    "        return {\n",
    "            'duration': 185,  # Fallback duration for Imagine\n",
    "            'onset_times': [],\n",
    "            'beat_times': [],\n",
    "            'vocal_segments': [{'start': 5, 'end': 180}],  # Assume most of song has vocals\n",
    "            'tempo': 120\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "287c81b7-01a6-4102-9ab1-bcd9bd436241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_audio_analysis(y, sr, times, spectral_centroids, onset_times, vocal_segments):\n",
    "    \"\"\"Plot audio analysis for debugging - FIXED\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot waveform\n",
    "    plt.subplot(3, 1, 1)\n",
    "    librosa.display.waveshow(y, sr=sr, alpha=0.6)\n",
    "    plt.title('Audio Waveform')\n",
    "    plt.ylabel('Amplitude')\n",
    "    \n",
    "    # Plot spectral centroids\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(times, spectral_centroids, label='Spectral Centroid', color='r', linewidth=1)\n",
    "    plt.axhline(y=0.4, color='g', linestyle='--', label='Vocal Threshold')\n",
    "    plt.title('Spectral Centroid (Vocal Activity Indicator)')\n",
    "    plt.ylabel('Normalized Value')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot onsets and vocal segments\n",
    "    plt.subplot(3, 1, 3)\n",
    "    for segment in vocal_segments:\n",
    "        plt.axvspan(segment['start'], segment['end'], alpha=0.3, color='red', label='Vocal Segments' if segment == vocal_segments[0] else \"\")\n",
    "    \n",
    "    for onset in onset_times:\n",
    "        plt.axvline(x=onset, color='blue', alpha=0.7, linestyle='--', label='Onsets' if onset == onset_times[0] else \"\")\n",
    "    \n",
    "    plt.title('Vocal Segments and Musical Onsets')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Detection')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    os.makedirs('../data', exist_ok=True)\n",
    "    plt.savefig('../data/audio_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"ğŸ“Š Analysis plot saved: ../data/audio_analysis.png\")\n",
    "    plt.close()\n",
    "\n",
    "def assign_lyrics_to_segments(lyrics_text, audio_analysis):\n",
    "    \"\"\"Intelligently assign lyrics to vocal segments - IMPROVED\"\"\"\n",
    "    lines = [line.strip() for line in lyrics_text.split('\\n') if line.strip()]\n",
    "    \n",
    "    if not lines:\n",
    "        return None\n",
    "    \n",
    "    vocal_segments = audio_analysis.get('vocal_segments', [])\n",
    "    onset_times = audio_analysis.get('onset_times', [])\n",
    "    duration = audio_analysis.get('duration', 180)\n",
    "    \n",
    "    print(f\"ğŸ“ Assigning {len(lines)} lyrics lines to {len(vocal_segments)} vocal segments\")\n",
    "    \n",
    "    # If we have vocal segments, distribute lyrics among them\n",
    "    if vocal_segments:\n",
    "        lyrics_with_timing = []\n",
    "        total_vocal_duration = sum(seg['end'] - seg['start'] for seg in vocal_segments)\n",
    "        \n",
    "        # Estimate words per second in vocal sections\n",
    "        total_words = sum(len(line.split()) for line in lines)\n",
    "        words_per_second = total_words / total_vocal_duration if total_vocal_duration > 0 else 2\n",
    "        \n",
    "        current_line_idx = 0\n",
    "        current_time = 0\n",
    "        \n",
    "        for segment in vocal_segments:\n",
    "            seg_start = segment['start']\n",
    "            seg_end = segment['end']\n",
    "            seg_duration = seg_end - seg_start\n",
    "            \n",
    "            # Estimate how many lines fit in this segment based on word count\n",
    "            lines_in_segment = []\n",
    "            while current_line_idx < len(lines):\n",
    "                line = lines[current_line_idx]\n",
    "                word_count = len(line.split())\n",
    "                estimated_duration = word_count / words_per_second\n",
    "                \n",
    "                # If adding this line doesn't exceed segment duration, add it\n",
    "                if current_time + estimated_duration <= seg_duration:\n",
    "                    lines_in_segment.append(line)\n",
    "                    current_time += estimated_duration\n",
    "                    current_line_idx += 1\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            # Assign timing to lines in this segment\n",
    "            if lines_in_segment:\n",
    "                line_duration = seg_duration / len(lines_in_segment)\n",
    "                for i, line in enumerate(lines_in_segment):\n",
    "                    line_start = seg_start + (i * line_duration)\n",
    "                    line_end = seg_start + ((i + 1) * line_duration)\n",
    "                    \n",
    "                    lyrics_with_timing.append({\n",
    "                        'text': line,\n",
    "                        'start_time': line_start,\n",
    "                        'end_time': line_end\n",
    "                    })\n",
    "            \n",
    "            current_time = 0  # Reset for next segment\n",
    "        \n",
    "        # Fill any remaining lines at the end using simple distribution\n",
    "        remaining_lines = len(lines) - current_line_idx\n",
    "        if remaining_lines > 0:\n",
    "            print(f\"âš ï¸ {remaining_lines} lines not assigned to vocal segments, using fallback timing\")\n",
    "            time_per_line = duration / len(lines)\n",
    "            for i in range(current_line_idx, len(lines)):\n",
    "                start_time = i * time_per_line\n",
    "                end_time = (i + 1) * time_per_line\n",
    "                lyrics_with_timing.append({\n",
    "                    'text': lines[i],\n",
    "                    'start_time': start_time,\n",
    "                    'end_time': end_time\n",
    "                })\n",
    "            \n",
    "    else:\n",
    "        # Fallback: simple linear timing\n",
    "        print(\"âš ï¸ No vocal segments, using linear timing\")\n",
    "        lyrics_with_timing = []\n",
    "        time_per_line = duration / len(lines)\n",
    "        for i, line in enumerate(lines):\n",
    "            lyrics_with_timing.append({\n",
    "                'text': line,\n",
    "                'start_time': i * time_per_line,\n",
    "                'end_time': (i + 1) * time_per_line\n",
    "            })\n",
    "    \n",
    "    return lyrics_with_timing\n",
    "\n",
    "def get_current_lyric(current_time, lyrics_with_timing):\n",
    "    \"\"\"Find which lyric should be displayed at current time\"\"\"\n",
    "    for lyric in lyrics_with_timing:\n",
    "        if lyric['start_time'] <= current_time < lyric['end_time']:\n",
    "            return lyric['text']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a93d69c-31c9-4812-8757-0fe3320f54d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_audio_synced_video(song_id=songId, plot_analysis=True, max_duration=None):\n",
    "    \"\"\"Create video with audio-analysis-based lyrics synchronization - WITH DURATION LIMIT\"\"\"\n",
    "    # Get song data\n",
    "    sql = '''\n",
    "    SELECT * FROM songs\n",
    "    WHERE name LIKE \"imagine\"\n",
    "    '''\n",
    "    songs = pd.read_sql(sql, engine)\n",
    "    songId = songs['id'].iloc[0]\n",
    "    try:\n",
    "        # Get song data\n",
    "        query = f\"\"\"\n",
    "        SELECT s.name as song_name, s.location as audio_file,\n",
    "               l.content as lyrics, a.first_name, a.last_name\n",
    "        FROM songs s \n",
    "        JOIN lyrics l ON s.id = l.song_id \n",
    "        JOIN artists a ON s.artist_id = a.id \n",
    "        WHERE s.id = {song_id}\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.read_sql(query, engine)\n",
    "        song_data = df.iloc[0]\n",
    "        \n",
    "        print(f\"ğŸµ Creating AUDIO-SYNCED video for: {song_data['song_name']}\")\n",
    "\n",
    "# Construct file paths\n",
    "        audio_dir = os.path.join(r\"C:\\ruby\\music\\public\\uploads\\song\\location\", str(song_id))\n",
    "        audio_path = os.path.join(audio_dir, song_data['audio_file'])\n",
    "        background_image_path = os.path.join(audio_dir, \"Folder.jpg\")\n",
    "        \n",
    "        print(f\"ğŸ”Š Audio: {os.path.basename(audio_path)}\")\n",
    "        print(f\"ğŸ–¼ï¸ Background: {os.path.basename(background_image_path)}\")\n",
    "        \n",
    "        if not os.path.exists(audio_path):\n",
    "            print(\"âŒ Audio file not found\")\n",
    "            return None\n",
    "        \n",
    "        # Perform audio analysis\n",
    "        audio_analysis = detect_vocal_segments(audio_path, plot_analysis=plot_analysis)\n",
    "        \n",
    "        # Load audio clip\n",
    "        audio_clip = AudioFileClip(audio_path)\n",
    "        full_duration = audio_analysis.get('duration', audio_clip.duration)\n",
    "\n",
    "# APPLY DURATION LIMIT\n",
    "        if max_duration:\n",
    "            duration = min(max_duration, full_duration)\n",
    "            print(f\"â±ï¸ Using LIMITED duration: {duration:.1f}s (max_duration={max_duration}s)\")\n",
    "        else:\n",
    "            duration = full_duration\n",
    "            print(f\"â±ï¸ Using FULL duration: {duration:.1f}s\")\n",
    "        \n",
    "        # Trim audio if needed\n",
    "        if max_duration and full_duration > max_duration:\n",
    "            audio_clip = audio_clip.subclip(0, duration)\n",
    "        \n",
    "        # Assign lyrics to timing segments (within the limited duration)\n",
    "        lyrics_with_timing = assign_lyrics_to_segments(song_data['lyrics'], audio_analysis)\n",
    "        \n",
    "        if not lyrics_with_timing:\n",
    "            print(\"âŒ Could not assign lyrics timing\")\n",
    "            return None\n",
    "\n",
    "# Filter lyrics to only include those within the limited duration\n",
    "        if max_duration:\n",
    "            lyrics_with_timing = [lyric for lyric in lyrics_with_timing if lyric['start_time'] < duration]\n",
    "            # Adjust the end time of the last lyric to match the limited duration\n",
    "            if lyrics_with_timing and lyrics_with_timing[-1]['end_time'] > duration:\n",
    "                lyrics_with_timing[-1]['end_time'] = duration\n",
    "        \n",
    "        print(f\"ğŸ“ Successfully assigned {len(lyrics_with_timing)} lyrics lines\")\n",
    "        print(f\"â±ï¸ Video duration: {duration:.1f}s ({duration/60:.1f} minutes)\")\n",
    "        \n",
    "        # Video settings\n",
    "        fps = 24\n",
    "        width, height = 640, 480\n",
    "\n",
    "        def make_synced_frame(t):\n",
    "            try:\n",
    "                # Load background\n",
    "                if os.path.exists(background_image_path):\n",
    "                    bg_image = Image.open(background_image_path)\n",
    "                    bg_image = bg_image.resize((width, height), Image.Resampling.LANCZOS)\n",
    "                    frame = np.array(bg_image)\n",
    "                else:\n",
    "                    frame = np.full((height, width, 3), [40, 40, 80], dtype=np.uint8)\n",
    "                \n",
    "                # Convert to PIL for text drawing\n",
    "                pil_img = Image.fromarray(frame)\n",
    "                draw = ImageDraw.Draw(pil_img)\n",
    "                \n",
    "                # Load font\n",
    "                try:\n",
    "                    font = ImageFont.truetype(\"arial.ttf\", 32)\n",
    "                except:\n",
    "                    try:\n",
    "                        font = ImageFont.truetype(\"C:/Windows/Fonts/arial.ttf\", 32)\n",
    "                    except:\n",
    "                        font = ImageFont.load_default()\n",
    "                \n",
    "                # Get current lyric based on audio analysis\n",
    "                current_line = get_current_lyric(t, lyrics_with_timing)\n",
    "\n",
    "                if current_line:\n",
    "                    # Calculate text position\n",
    "                    try:\n",
    "                        bbox = draw.textbbox((0, 0), current_line, font=font)\n",
    "                    except AttributeError:\n",
    "                        bbox = draw.textsize(current_line, font=font)\n",
    "                        bbox = (0, 0, bbox[0], bbox[1])\n",
    "                    \n",
    "                    text_width = bbox[2] - bbox[0]\n",
    "                    text_height = bbox[3] - bbox[1]\n",
    "                    x = (width - text_width) // 2\n",
    "                    y = (height - text_height) // 2\n",
    "                    \n",
    "                    # Semi-transparent background for text\n",
    "                    padding = 10\n",
    "                    draw.rectangle([\n",
    "                        x - padding, y - padding,\n",
    "                        x + text_width + padding, y + text_height + padding\n",
    "                    ], fill=(0, 0, 0, 180))\n",
    "                    \n",
    "                    # Text with shadow for readability\n",
    "                    shadow_color = (0, 0, 0)\n",
    "                    text_color = (255, 255, 255)\n",
    "                    \n",
    "                    # Shadow\n",
    "                    draw.text((x+2, y+2), current_line, font=font, fill=shadow_color)\n",
    "                    # Main text\n",
    "                    draw.text((x, y), current_line, font=font, fill=text_color)\n",
    "                \n",
    "                return np.array(pil_img)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Frame error at {t:.1f}s: {e}\")\n",
    "                return np.zeros((height, width, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Create video\n",
    "        print(\"ğŸ¬ Creating audio-synced video frames...\")\n",
    "        video = VideoClip(make_synced_frame, duration=duration)\n",
    "        video = video.set_audio(audio_clip)\n",
    "        \n",
    "        # Export\n",
    "        output_dir = '../data/videos'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Include duration in filename if limited\n",
    "        if max_duration:\n",
    "            output_file = os.path.join(output_dir, f\"{song_data['song_name']}_audio_synced_{max_duration}s.mp4\")\n",
    "        else:\n",
    "            output_file = os.path.join(output_dir, f\"{song_data['song_name']}_audio_synced_full.mp4\")\n",
    "        \n",
    "        print(\"ğŸ“¹ Exporting audio-synced video...\")\n",
    "        video.write_videofile(\n",
    "            output_file, \n",
    "            fps=fps, \n",
    "            codec='libx264',\n",
    "            audio_codec='aac',\n",
    "            verbose=False,\n",
    "            logger=None\n",
    "        )\n",
    "\n",
    "        print(f\"âœ… AUDIO-SYNCED video created: {output_file}\")\n",
    "        print(f\"ğŸ“Š File size: {os.path.getsize(output_file) / (1024*1024):.1f} MB\")\n",
    "        \n",
    "        # Display timing information\n",
    "        print(\"\\nğŸ“‹ Lyrics Timing Summary:\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, lyric in enumerate(lyrics_with_timing):\n",
    "            print(f\"{i+1:2d}. {lyric['start_time']:5.1f}s - {lyric['end_time']:5.1f}s: {lyric['text'][:40]}{'...' if len(lyric['text']) > 40 else ''}\")\n",
    "        \n",
    "        # Clean up\n",
    "        video.close()\n",
    "        audio_clip.close()\n",
    "        \n",
    "        return output_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Audio-synced video error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8736403a-9ea6-4607-847b-c66f278d9527",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ¬ CREATING AUDIO-ANALYSIS SYNCED VIDEO\n",
      "======================================================================\n",
      "ğŸµ Creating AUDIO-SYNCED video for: The Older I Get\n",
      "ğŸ”Š Audio: The_Older_I_Get__Alan_Jackson__Lyrics_.mp3\n",
      "ğŸ–¼ï¸ Background: Folder.jpg\n",
      "ğŸ¤ Analyzing audio for vocal segments...\n",
      "ğŸ“Š Audio loaded: 236.65s, SR: 48000Hz\n",
      "ğŸ“Š Extracting audio features...\n",
      "ğŸ“ Spectral centroids shape: (1, 22186)\n",
      "ğŸ“ Times shape: (22186,), Normalized centroids shape: (22186,)\n",
      "âš ï¸ No vocal segments detected, using onset-based segmentation\n",
      "ğŸ“Š Analysis plot saved: ../data/audio_analysis.png\n",
      "âœ… Detected 483 vocal segments\n",
      "âœ… Detected 484 musical onsets\n",
      "âŒ Audio analysis error: unsupported format string passed to numpy.ndarray.__format__\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC1\\AppData\\Local\\Temp\\ipykernel_840372\\3083768794.py\", line 96, in detect_vocal_segments\n",
      "    print(f\"ğŸµ Estimated tempo: {tempo:.1f} BPM\")  # FIXED: Now tempo is a float\n",
      "                                ^^^^^^^^^^^\n",
      "TypeError: unsupported format string passed to numpy.ndarray.__format__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â±ï¸ Using LIMITED duration: 60.0s (max_duration=60s)\n",
      "ğŸ“ Assigning 45 lyrics lines to 1 vocal segments\n",
      "ğŸ“ Successfully assigned 15 lyrics lines\n",
      "â±ï¸ Video duration: 60.0s (1.0 minutes)\n",
      "ğŸ¬ Creating audio-synced video frames...\n",
      "ğŸ“¹ Exporting audio-synced video...\n",
      "âœ… AUDIO-SYNCED video created: ../data/videos\\The Older I Get_audio_synced_60s.mp4\n",
      "ğŸ“Š File size: 1.5 MB\n",
      "\n",
      "ğŸ“‹ Lyrics Timing Summary:\n",
      "--------------------------------------------------\n",
      " 1.   5.0s -   8.9s: 18,the older i get\n",
      " 2.   8.9s -  12.8s: 22,the more i think\n",
      " 3.  12.8s -  16.7s: 26,you only get a minute\n",
      " 4.  16.7s -  20.6s: 29,better live while you're in it\n",
      " 5.  20.6s -  24.4s: 30,cause it's gone in a blink\n",
      " 6.  24.4s -  28.3s: 34,and the older i get\n",
      " 7.  28.3s -  32.2s: 38,the truer it is\n",
      " 8.  32.2s -  36.1s: 42,it's the people you love\n",
      " 9.  36.1s -  40.0s: 46,not the money and stuff\n",
      "10.  40.0s -  43.9s: 47,that makes you rich\n",
      "11.  43.9s -  47.8s: 51,and if they found a fountain of youth\n",
      "12.  47.8s -  51.7s: 54,i wouldn't drink a drop\n",
      "13.  51.7s -  55.6s: 58,and that's the truth\n",
      "14.  55.6s -  59.4s: 60,funny how it feels i'm just getting t...\n",
      "15.  59.4s -  60.0s: 63,my best years yet\n",
      "\n",
      "ğŸ‰ SUCCESS! Audio-synced video created: ../data/videos\\The Older I Get_audio_synced_60s.mp4\n",
      "\n",
      "âœ¨ Features:\n",
      "   âœ… Automatic vocal segment detection\n",
      "   âœ… Intro handling (no lyrics during instrumental intro)\n",
      "   âœ… Beat and onset detection for better timing\n",
      "   âœ… Spectral analysis for vocal activity\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if not already installed\n",
    "def install_required_packages():\n",
    "    \"\"\"Install required audio analysis packages\"\"\"\n",
    "    try:\n",
    "        import librosa\n",
    "        import matplotlib\n",
    "    except ImportError:\n",
    "        print(\"ğŸ“¦ Installing required audio analysis packages...\")\n",
    "        import subprocess\n",
    "        import sys\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"librosa\", \"matplotlib\"])\n",
    "        print(\"âœ… Packages installed successfully\")\n",
    "\n",
    "# Run the audio-synced version\n",
    "if __name__ == \"__main__\":\n",
    "    # Install required packages\n",
    "    install_required_packages()\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"ğŸ¬ CREATING AUDIO-ANALYSIS SYNCED VIDEO\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    result = create_audio_synced_video(song_id=songId, plot_analysis=True, max_duration=60)\n",
    "    \n",
    "    if result:\n",
    "        print(f\"\\nğŸ‰ SUCCESS! Audio-synced video created: {result}\")\n",
    "        print(\"\\nâœ¨ Features:\")\n",
    "        print(\"   âœ… Automatic vocal segment detection\")\n",
    "        print(\"   âœ… Intro handling (no lyrics during instrumental intro)\")\n",
    "        print(\"   âœ… Beat and onset detection for better timing\")\n",
    "        print(\"   âœ… Spectral analysis for vocal activity\")\n",
    "    else:\n",
    "        print(\"\\nâŒ Audio-synced video creation failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8931a0ad-1254-4dc6-bb0f-0c2437a7badc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
