{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa39818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7edddf43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/name-ttl.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_data_path = \"../data/\"\n",
    "file_name = 'name-ttl.csv'\n",
    "input_file = inp_data_path + file_name\n",
    "input_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "740e784f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACE\\n', 'ADVANC\\n', 'AEONTS\\n', 'AH\\n', 'AIE\\n', 'AIMIRT\\n', 'AIT\\n', 'AJ\\n', 'AMATA\\n', 'ANAN\\n', 'AOT\\n', 'AP\\n', 'ASIAN\\n', 'ASK\\n', 'ASP\\n', 'ASW\\n', 'AWC\\n', 'BA\\n', 'BAM\\n', 'BANPU\\n', 'BAY\\n', 'BBL\\n', 'BCH\\n', 'BCP\\n', 'BCPG\\n', 'BCT\\n', 'BDMS\\n', 'BE8\\n', 'BEAUTY\\n', 'BEC\\n', 'BEM\\n', 'BGC\\n', 'BGRIM\\n', 'BH\\n', 'BJC\\n', 'BKI\\n', 'BLA\\n', 'BLAND\\n', 'BPP\\n', 'BTS\\n', 'BTSGIF\\n', 'CBG\\n', 'CENTEL\\n', 'CHG\\n', 'CK\\n', 'CKP\\n', 'COM7\\n', 'CPALL\\n', 'CPAXT\\n', 'CPF\\n', 'CPN\\n', 'CPNCG\\n', 'CPNREIT\\n', 'CPTGF\\n', 'CRC\\n', 'DCC\\n', 'DCON\\n', 'DELTA\\n', 'DIF\\n', 'DOHOME\\n', 'DRT\\n', 'EA\\n', 'EASTW\\n', 'ECL\\n', 'EGATIF\\n', 'EGCO\\n', 'EPG\\n', 'FORTH\\n', 'FPT\\n', 'FSMART\\n', 'FTREIT\\n', 'GC\\n', 'GFPT\\n', 'GGC\\n', 'GLOBAL\\n', 'GPSC\\n', 'GRAMMY\\n', 'GULF\\n', 'GUNKUL\\n', 'GVREIT\\n', 'HANA\\n', 'HFT\\n', 'HMPRO\\n', 'HTC\\n', 'ICHI\\n', 'III\\n', 'ILM\\n', 'IMH\\n', 'IMPACT\\n', 'INOX\\n', 'INTUCH\\n', 'IP\\n', 'IRPC\\n', 'IVL\\n', 'JASIF\\n', 'JMART\\n', 'JMT\\n', 'KBANK\\n', 'KCE\\n', 'KEX\\n', 'KGI\\n', 'KKP\\n', 'KSL\\n', 'KTB\\n', 'KTC\\n', 'KYE\\n', 'LALIN\\n', 'LANNA\\n', 'LH\\n', 'LHFG\\n', 'LHK\\n', 'LIT\\n', 'LPF\\n', 'LPH\\n', 'LPN\\n', 'M\\n', 'MAJOR\\n', 'MBAX\\n', 'MC\\n', 'MCS\\n', 'MEGA\\n', 'MINT\\n', 'MST\\n', 'MTC\\n', 'NER\\n', 'NOBLE\\n', 'ONEE\\n', 'OR\\n', 'ORI\\n', 'OSP\\n', 'PAP\\n', 'PCSGH\\n', 'PDG\\n', 'PLANB\\n', 'POPF\\n', 'PREB\\n', 'PRM\\n', 'PSH\\n', 'PSL\\n', 'PTG\\n', 'PTL\\n', 'PTT\\n', 'PTTEP\\n', 'PTTGC\\n', 'QH\\n', 'RATCH\\n', 'RBF\\n', 'RCL\\n', 'RJH\\n', 'ROJNA\\n', 'RS\\n', 'S11\\n', 'SABUY\\n', 'SAPPE\\n', 'SAT\\n', 'SAWAD\\n', 'SC\\n', 'SCB\\n', 'SCC\\n', 'SCCC\\n', 'SCGP\\n', 'SENA\\n', 'SGP\\n', 'SINGER\\n', 'SIRI\\n', 'SIS\\n', 'SJWD\\n', 'SKN\\n', 'SKR\\n', 'SMPC\\n', 'SNC\\n', 'SPALI\\n', 'SPC\\n', 'SPCG\\n', 'SPRC\\n', 'SPRIME\\n', 'SSP\\n', 'STA\\n', 'STANLY\\n', 'STEC\\n', 'STGT\\n', 'SUPER\\n', 'SUPEREIF\\n', 'SVI\\n', 'SYNEX\\n', 'TASCO\\n', 'TCAP\\n', 'TFFIF\\n', 'TFG\\n', 'THANI\\n', 'THG\\n', 'TIDLOR\\n', 'TIPH\\n', 'TIPCO\\n', 'TISCO\\n', 'TK\\n', 'TKN\\n', 'TKS\\n', 'TMT\\n', 'TMW\\n', 'TOA\\n', 'TOP\\n', 'TPIPL\\n', 'TPIPP\\n', 'TQM\\n', 'TR\\n', 'TRUE\\n', 'TSE\\n', 'TSTH\\n', 'TTA\\n', 'TTB\\n', 'TTLPF\\n', 'TTW\\n', 'TU\\n', 'TVO\\n', 'TYCN\\n', 'UTP\\n', 'VGI\\n', 'VIBHA\\n', 'VNG\\n', 'WHA\\n', 'WHAIR\\n', 'WHART\\n', 'WHAUP\\n', 'WICE\\n', 'WORK\\n']\n"
     ]
    }
   ],
   "source": [
    "# Read stock names from the 'name-ttl.csv' file\n",
    "with open(input_file, 'r') as file:\n",
    "    stock_names = file.readlines()\n",
    "print(stock_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4302bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "# Create the output CSV file and write the headers\n",
    "with open('stock_data.csv', 'w', newline='') as file:\n",
    "    csv_writer = csv.writer(file)\n",
    "    csv_writer.writerow(['i', 'name', 'today-low', '52w-low', 'today-high', '52w-high'])\n",
    "\n",
    "    # For each stock name\n",
    "    for stock_name in stock_names:\n",
    "\n",
    "        # Generate the customized URL\n",
    "        url = f'https://www.set.or.th/th/market/product/stock/quote/{stock_name}/price'\n",
    "\n",
    "        # Commented-out code to fetch the webpage and parse it\n",
    "        # We comment out this section to avoid incurring any costs\n",
    "        #\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        #\n",
    "        #today_low  = soup.find_all('span', class_='title-font-family fs-16px fw-bolder me-auto lh-1')[0].text.strip()\n",
    "        try:\n",
    "           today_low = soup.find_all('span', class_='title-font-family fs-16px fw-bolder me-auto lh-1')[1].get_text()\n",
    "        except IndexError:\n",
    "           today_low = f'{stock_name}. Moving to next stock.'\n",
    "        continue\n",
    "        \n",
    "        #_52w_low   = soup.find_all('span', class_='title-font-family fs-16px fw-bolder me-auto lh-1')[1].text.strip()\n",
    "        try:\n",
    "           _52w_low = soup.find_all('span', class_='title-font-family fs-16px fw-bolder me-auto lh-1')[2]\n",
    "        except IndexError:\n",
    "           print(f'Could not get _52w__low for stock {stock_name}. Moving to next stock.')\n",
    "        continue    \n",
    "        \n",
    "        # today_high = soup.find_all('span', class_='title-font-family fs-16px fw-bolder lh-1')\n",
    "        try:\n",
    "           today_high = soup.find_all('span', class_='title-font-family fs-16px fw-bolder lh-1')\n",
    "        except IndexError:\n",
    "           print(f'Could not get today_high for stock {stock_name}. Moving to next stock.')\n",
    "        continue\n",
    "        \n",
    "        #_52w_high  = soup.find_all('span', class_='title-font-family fs-16px fw-bolder lh-1')\n",
    "        try:\n",
    "           _52w_high = soup.find_all('span', class_='title-font-family fs-16px fw-bolder lh-1')\n",
    "        except IndexError:\n",
    "           print(f'Could not get today_high for stock {stock_name}. Moving to next stock.')\n",
    "        continue\n",
    "\n",
    "        # Create a row of data\n",
    "        # In a running notebook, the commented-out code above would fetch the real data\n",
    "        # Here we just use placeholder strings\n",
    "        i = i + 1\n",
    "        row = [i, stock_name, today_low, _52w_low, today_high, _52w_high]\n",
    "        csv_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96ef433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag_eps = soup.find(\"'span', class_='title-font-family fs-16px fw-bolder me-auto lh-1'\")\n",
    "#print(tag_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b8e739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
